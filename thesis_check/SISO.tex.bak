\chapter{Generalized frequency division multiplexing single input single output}\label{sec:GFDMSISO}
\section{System model}\label{part:SMSISO}
In this subsection will be explained the system model for the GFDM . We consider the system where transmitted signal is sent through the channel. The channel in physical meaning is the number of multipath propagation components from transmitter to the receiver or the convolution of the transmitted signal with some channel profile.  We  explain the received signal as matrix product between convolution matrix and the transmitted data array \eqref{siso_1}, where $\mathbf{y}$ is received array, $\mathbf{x}$ is transmitted array and $\mathbf{H}$ is channel convolution matrix. Also the additive white Gaussian noise is assumed. The  different channel models are considered in the thesis\eqref{siso_2}\eqref{siso_3}\cite{Book21}.
The transmitted data is the third order PARATUCK2 tensor in the vectorized or unfolding form. The symbol matrix $\mathbf{S}$ introduced as the core matrix in the PARATUCK2 model\cite{Book6}. The symbols are written in the core matrix without any correction.
 Each column in the $\mathbf{C^{[a]}}$ matrix corresponds to the certain sub-carrier frequency for the stream modulation\eqref{siso_4}\eqref{siso_5}.The $\mathbf{C^{[a]}}$ matrix is constructed as the sub-carrier frequency  time samples in the each column, where column $i$ will correspond to the $i$ sub-carrier in the GFDM system. The overall equation to the $\mathbf{C^{[a]}}$ construction is explained in the \eqref{siso_1}. 
 Each column in the $\mathbf{C^{[b]}}$ define spread of the certain symbol over the all transmission block \eqref{siso_6}\cite{Book12}.  Elements in the columns are the time filter functions for the symbols. Each column is the shifted version of the other. The shift between near columns is equal to the $ T/T_s$ \eqref{siso_7}. The time filters functions are the root-raised cosine filter with adjustable $\alpha$ coefficient.

 The  $\mathbf{B}$ matrix become $\mathbf{b}$ array
and in the physical meaning corresponds to the time variation inside the one transmission block for different symbols or as selection coefficients for the different time slots\cite{Book34}.  We assume that system is linear time invariant and therefore $\mathbf{b}$ become array with all-ones structure \eqref{siso_8}.

The  $\mathbf{A}$ matrix become $\mathbf{a}$ array and in the physical meaning corresponds to the transmission coefficient for each sub-carrier frequency stream or  selection array for sub-carriers inside of the one transmission block \eqref{siso_10}. We will consider the system where the $\mathbf{a}$ will has two typical structures. First is the array with all-ones in case if there is no overlapping in the frequency domain systems and known to the receiver. In the second case the values in the $\mathbf{a}$ is unknown for the receiver and have random variables from the range $[0,1]$

The transmitted data is defined in equation \eqref{siso_12} where each matrix is explained above. Regarding to the chapter X the PARATUCK2 model can be defined in the different equations \eqref{siso_13} \eqref{siso_14} with vectorization operation for the resulting tensor. The vectorized model is sensible to transpose of the resulting matrix and to the order change.

\section{Additive white Gaussian noise channel}\label{part:AWGN}
In this section we assume the GFDM transmitter-receiver pair in the SISO case with the additive white Gaussian noise at the receiver and memoryless flat-frequency channel\cite{Book30}. Therefore system model at the receiver become equation \eqref{siso_15}.

\subsection{Zero forcing solution}
The receiver can find the optimal transmitted values via optimization task solution\cite{Book11}.  The demodulation problem can be rewritten in the residual form. We can rewrite $\mathbf{y}$ as the product of the known modulation matrix with the vectorized symbols matrix \eqref{siso_ls_1}. We introduce the matrix $\mathbf{\Omega}_1$ in \eqref{siso_ls_2} and define $vec(\mathbf{y)}$ as the matrix product between the $\mathbf{\Omega}_1$ and estimated $vec(\mathbf{\widehat{S}})$ \eqref{siso_ls_3}. We define residual equation which is difference between received data and the estimated at the receiver symbols \eqref{siso_ls_4}. The  $\mathbf{\Omega}_1$ is given from the paper \cite{Book26}. If the $\mathbf{a}$ and $\mathbf{b}$ have all-ones structure we can neglect them and take as the Khatri-Rao product between $\mathbf{C^{[a]}}$ and $\mathbf{C^{[b]}}$ \eqref{siso_ls_4}
The receiver must solve the system of linear equations. The problem can be solved in the second norm sense \eqref{siso_ls_5} and also known as the Zero-Forced receiver \cite{Book24}.The second norm function is convex, with one global minimum point. To find minimum point the receiver find partial derivative of the objective function \eqref{siso_ls_6}, equate it to the zero and solve the system of linear equations. The estimated $\mathbf{S}$ matrix is complex valued, which makes objective function non-holomorphic. To solve optimization problem we have used the Wirtinger calculus and find the partial derivative with respect to the $vec(\mathbf{\widehat{S}}^*)$ and equate it to the zero. Next calculations steps come to the classical  least squares solution of the objective function \eqref{siso_ls_10}\cite{Book24}. 
\subsection{Matched filter solution}
Another solution for the problem is so called Matched filter receiver. The receiver  multiply received data with the hermitian transpose of the modulation matrix\cite{Book25}. We can look at the singular value decomposition of the $\mathbf{\Omega}_1$ \eqref{siso_mf_1} and write in the same form the inverse of the matrix due to the unitary structure of the matrix $\mathbf{U}$ \eqref{siso_mf_2}. The inverse of the $\mathbf{\Sigma}$ is inverse of the each element of the matrix due to the diagonal structure\cite{Book25}. With increasing of the $\alpha$ coefficient in the time filter the condition number of the $\mathbf{\Omega}_1$\eqref{siso_mf_4} decrease and inverse of the matrix will increase noise components with decreasing minimal singular value of the $\mathbf{\Omega}_1$\eqref{siso_mf_4}. We can multiply the received data with hermitian of the $\mathbf{\Omega}_1$\eqref{siso_mf_5}\cite{Book24}. In that case the structure of the singular components inside of the  calculated matrix become the same and noise components will have the same power\eqref{siso_mf_6}.

\section{Selection coefficients search}\label{part:SCSSISO}
Explained above the coefficients from the $\mathbf{a}$ are used as the selection coefficients for the sub-carriers. In the GFDM system is allowed to disable some sub-carriers to decrease interference with other systems which work in the same frequency range\cite{Book25}.The transmitted may use the spectrum sensing approach and doesn't use the number of subcarriers inside of the transmission block. Receiver will not know which sub-carriers are used and must estimate information from the received data\eqref{siso_s_1}. The information about used sub-carriers may transmitted as additional to find coefficients at the receiver side.
We can use the PARATUCK2 model to estimate information about used subcarriers at the receiver. The received signal is defined as \eqref{siso_s_1}, where the selection coefficients become in the $\mathbf{a}$

We formulate equation to vectorize the $\mathbf{a}$ from the right hand side as \eqref{siso_s_2} and write the problem statement to find the coefficients as the residual between received signal and estimated channel \eqref{siso_s_3}.
\subsection{Semi-blind receiver}
The receiver estimate the transmission coefficients and the symbols in case if will know at least one symbol at each sub-carrier frequency. The receiver will estimate in the certain time slot the transmission coefficient for the overall block of the data and will find all other symbols according to the LS solution or optimization algorithm. We should write the objective function and minimize it to implement the semi-blind receiver. The unknown variables are $\mathbf{\widehat{S}}$ and the $\mathbf{a}$. The known symbols is added in the objective function as constraint or via decreasing number of the variables.
 Second way decreases scale of the objective function, but problem formulation  become non-trivial. We add known symbol information as the additional constraint in the objective function  \eqref{siso_sm_1}. There are two ways to solve the task, joint and  approximated solutions. The joint solution consider  all dependences between $r_1,r_2,r_3$. The second approach calculate solution for three residual function separately and use non-linear optimization process to stack three equations in one. We implemented both of them.
\subsection{Approximated semi-blind receiver}
 Problem statement is defined in \eqref{siso_sm_2}. We minimize objective function with assumption: $\mathbf{r}_1$ and $\mathbf{r}_2$ does not depend from each other.  We don't used the Lagrangian multipliers to analytical optimization and find minimum point in the optimization process. The residual function $r_1$ corresponds to the objective function with vectorized symbol matrix $\mathbf{\widehat{S}}$. The $\mathbf{\Omega}_1$ is defined previously and corresponds to the modulation matrix.
 The residual function $r_2$ corresponds to the objective function with vectorized array $\mathbf{a}$. The $\mathbf{\Omega}_2$ is defined previously and corresponds to the transmitted data with separated sub-carrier coefficients.
The residual function $r_3$ corresponds to the constraint for the known symbols, where $\mathbf{S}_{sel}$ become the selection matrix, where on the main diagonal is ones in points where $vec(\mathbf{\widehat{S}})$ is known. The $\mathbf{q}$ array is the array with vectorized known symbols in the $vec(\mathbf{\widehat{S}})$ and zeros in the unknown points.
We can stack \eqref{siso_sm_10}\eqref{siso_sm_9}\eqref{siso_sm_8} in one system of non-linear equations.There are many ways to sole the system of non-linear equations.
 There are two additional approaches which could be implemented in the Newton algorithm. One is the Powell-Wolf rule\cite{Book62}\cite{Book63} for the step-size variable adjust. The second is the Levenberg-Marquardt regularization\cite{Book66}\cite{Book68} algorithm. The main equation of the Newton algorithm for the non-linear equations is presented in the \eqref{siso_sm_11}, where $\mathbf{d}$ is the derivative array which is minimized to the zero and $J$ is the Jacobian matrix of the $\mathbf{d}$ array. The definition of the partial derivative array $\mathbf{d}$ array is  explained in the equation\eqref{siso_sm_13}. 
We must calculate partial derivative from the  $\mathbf{d}$ to find the Jacobian matrix \eqref{siso_sm_18}.Because the function\eqref{siso_sm_13} is holomorphic, we don't use the Wirtinger calculus in Jacobian calculation. We calculate partial derivative with respect to the $\delta \theta$ \eqref{siso_sm_19}. 
 The receiver solve the system of the linear equations at the each iteration and update the search vector for the next step\eqref{siso_sm_12}. The optimization algorithm decrease the derivative of residual to the zero, and converge due to the convexity of the second norm\cite{Book58}.

\subsection{Joint semi-blind receiver}
We can minimize the objective function \eqref{siso_jsm_1} without assumptions and approximations. General form makes implementation more complex. It should be noticed that $\mathbf{r}_1$ and the $\mathbf{r}_2$ is the same equations but explained from the different point of view: from the unknown symbols or unknown sub-carrier coefficients.  
We write the objective function. The function in non-holomorphic. We find the partial derivatives with Wirtinger calculus. We can use the \eqref{siso_jsm_3} property of the derivatives to find the derivatives separately for each function. To calculate the cross derivatives for the $\mathbf{r}_1^H\mathbf{r}_1$ with respect to the $\mathbf{a}^*$ we use the \eqref{siso_jsm_7} which allow to change the left hand part of equation, where $\mathbf{\widehat{a}}^*$ is clearly defined\cite{Book26}.
The optimization function become the system of non-linear equations. As explained previously, to solve the system of the non-linear equations we use the Newton method.The $\mathbf{d}$ is presented in the \eqref{siso_jsm_12}. The function is holomorphic\cite{Book61} and we can calculate Jacobian matrix  $\mathbf{J}$ without Wirtinger calculus \eqref{siso_jsm_11}. The $r_1$ and the $r_2$ is equal function in the different notation. We use this property when we calculate cross variable derivatives.  The resulting Jacobian matrix \eqref{siso_jsm_13} is different from the Jacobian matrix presented in the approximated solution \eqref{siso_jsm_13}

Joint solution converge faster in comparison with the approximated approach. Each iteration in the joint solution algorithm become computationally more expensive, but algorithm takes much less iterations.
\section{Frequency selective channel estimation}\label{part:FSCESISO}
\subsection{Approximated channel estimation}
In this section is considered model where channel has the multipath propagation components \eqref{siso_a_1}\eqref{siso_a_2}. We use assumption of maximal delay between first and the last multipath propagation components equal to the $T/T_s$ time samples. This assumption makes approach below only approximation of the channel orthogonalization .
We can implement the channel estimation approach without channel prefix in the start of the transmission block. We put the training symbol in the transmission block. 
Consider the matrix $\mathbf{H}$ in terms of parametric model. The matrix $\mathbf{H}$ has Toeplitz lower triangular structure\eqref{siso_a_3}\cite{Book5}. Each column in the $\mathbf{H}$ corresponds to the multipath components  for certain time sample. We assume that length of the channel is less than $T/T_s$. The matrix $\mathbf{H}$ has only $T/T_s$ non-zero elements in the each column. Maximal length of the cyclic prefix to estimate the channel equal to the $T/T_s$ samples in that case. 
The transmitter insert this prefix as predefined symbols in the first column in the matrix $\mathbf{S}$ \eqref{siso_a_5}. The first column in the matrix $\mathbf{S}$ corresponds to the first time slot for each sub-carrier stream\eqref{siso_a_6}. The knowledge of the symbols in the first column doesn't define the first $T/T_s$ time samples in the transmission block. The receiver doesn't know exactly the first $T/T_s$ samples of received data, even if the first $F$ symbols is known. Due to that fact the receiver will approximate the channel with the error \eqref{siso_a_13}\cite{Book23}. Define the matrix with training symbols\eqref{siso_a_5}.Define the matrix with unknown  symbols\eqref{siso_a_6}. The training signal from the transmitter will be written in the following form \eqref{}. The received signal will be written as following\eqref{}. The receiver can construct the following array from the known training symbols\eqref{} and define the convolution matrix from the known array. 

One approach to decrease channel estimation error is the adaptive $\alpha$ coefficient adjustment. The transmitter use two different $\alpha$ coefficients for the working time slots and for the test time slots. We use guard interval with length one symbol to avoid ICI and decrease interference for the certain symbols. Symbols with decreased ICI used as the cyclic prefix and increase estimation precision for the described above approach. 
The second approach to decrease uncertainty and increase precision is optimization algorithm. Algorithm estimate use additional double side interference cancellation. The joint symbol and multipath components estimation leads to the decrease of uncertainty with symbol estimation, and decrease probability of the error with the multipath component estimation. 
\subsection{Channel estimation}
The main equation of the received data \eqref{ce_2} can be rewritten with respect to the unknown channel model \eqref{ce_1}.

Where the $\mathbf{h}$ is the channel coefficients with known length $L+1$. The matrix $\mathbf{D}_{mod}$ is constructed via shifting and stacking of the transposed array $\mathbf{\Omega}_1vec(\mathbf{S})$\cite{Book53}.
As shown in the \eqref{ce_4} the receiver can estimate the channel is case if symbols are known\cite{Book47}. It should be noted that transmitter must know the length of the channel . The least squares solution is calculated as following in the previous parts with the Wirtinger calculus \eqref{ce_5}. The receiver calculate the pseudo-inverse of the matrix \eqref{ce_7}. The solution for the least squares problem is presented in the \eqref{ce_7}.

 In the practical case the transmission block is too large to them all with known symbols. The transmitter can fill number of the symbols with the known data and other as unknown to the receiver. The matrices $\mathbf{S}_{sel}$ and $\mathbf{S}_{sel unk}$ are constructed in the similar way. The matrices are the selection matrices with ones in the points where symbol transmitted with certain column of the $\mathbf{\Omega}_1$.


 The receiver must find both symbols and the channel values and perform the semi-blind receiver solution. To make the statement of the task separated from the known and unknown symbol part, which also decrease inter-symbol interference the receiver rewrite the task in the following notation \eqref{ce_17}.

 We write the received data as the sum of two array: known and unknown. The receiver also can divide the modulation matrix into the two parts: with columns corresponding to the known symbols and with other columns of the matrix $\mathbf{\Omega}_1$.
  With such equation the unknown symbols will estimated more precisely in comparison with simple ALS approach. The receiver construct the two residual equations and try to minimize them during the optimization task. The residual function based on the second norm to make the objective function convex. The optimization task can be solved with ALS and Newton algorithm. 
 
  The objective function is following\eqref{ce_als_1}.  We construct the partial derivative with respect to the unknown symbols and channel values. We used the Wirtinger calculus to find the derivative of the complex function. The derivative is written as the system of non-linear equations. We used ALS and Newton algorithms to solve the problem . 
 

The Newton algorithm solve the system of linear equations at each iteration for which given point \cite{Book62}. We must write the equation of the Jacobian matrix \eqref{ce_n_3} for the  partial derivatives to determine the solved at each iteration equation. To write the Jacobian matrix we use property of the equality of the different notations of the same function in the same point. The resulting Jacobian matrix is written as follows \eqref{ce_n_5}. 
The Newton algorithm may be regularized and written in the more stable form with the Powell-Wolf stepsize rule\cite{Book66} and Levenberg-Marquardt regularization approach \cite{Book65}. 
%It is also possible to use explained in the \cite{Book53}\cite{Book52} so called semi-blind receiver based regularization approached, but they request the estimation over number of the received blocks of the data.
\section{Simulation results}\label{part:SRSISO}
In this section we present simulation results for the GFDM system and algorithms which was reviewed in the chapter \ref{sec:GFDMSISO}.

Performance of the GFDM system in comparison with different $\alpha$ coefficients are obtained through simulation. The parameters of the system are tabulated in Table \eqref{tab:table1}. The GFDM system is simulated in the AWGN channel without coding. QPSK modulation scheme is used. The number of sub-carriers was $F=32$, samples for each symbol was $T/T_s=F$ The block size was $T_s=15$. The root-raised cosine filter was used with  list of roll-of-factors. In the roll-of factor test we measured the SER for the different $\alpha$ for the Zero-Forced receiver and matched filter. The resulting SER plot is shown for the zero forced receiver at fig. \eqref{fs_1} and  for the matched filter receiver at fig. \eqref{fs_2}.

Performance results of the GFDM selection coefficient estimation and semi-blind receiver are obtained through simulation. The parameters of the system are tabulated in Table \ref{tab:table2}. 

The GFDM system is simulated with AWGN channel. QPSK modulation scheme is used. The number of sub-carriers was $F=32$, samples for each symbol was $T/T_s=F$ The block size was $T_s=15$. The root-raised cosine filter was used with roll-of-factor $\alpha=0.5$. The selection coefficients was chosen as the random integer values in range from $0$ to $1$.  The results of the GFDM performance is presented in the two plots, at first \eqref{fs_3} is shown the SER in comparison with the case  if receiver know the original $\mathbf{a}$ with the Zero-Forced receiver and with case if receiver doesn't know the $\mathbf{a}$ . At second figure \eqref{fs_4} is shown the reconstruction error for the $\mathbf{a}$ .

There are additional plots for the joint and approximated algorithms comparison is shown at  fig.\eqref{fs_5} fig.\eqref{fs_6} fig.\eqref{fs_7}. The comparison results are obtained through simulation. The setup of the simulation is shown from the Table \ref{tab:table3}.The GFDM system is simulated with AWGN channel. QPSK modulation scheme is used. The parameters of the setup is the same as in the previous experiment. In the fig.\eqref{fs_5} is shown the typical reconstruction error convergence of the both of the algorithms per iterations. As the real minimum point is shown values of the residual between generated matrices and received data. In the fig.\eqref{fs_6} shown the time of the convergence of the algorithm with dependence for the SNR. In the fig.\eqref{fs_7} shown the typical convergence of the residual \eqref{sim:eq_1} of the both of the algorithms per iterations. As the real minimum point is shown values of the residual between generated matrices and received data.

The GFDM system semi-blind receiver is simulated in the frequency selective channel without coding. QPSK modulation scheme is used. The number of sub-carriers was $F=8$, samples for each symbol was $T/T_s=F$ The block size was $T_s=3$. The root-raised cosine filter was used with roll-of-factor $\alpha=1$. The length of the channel equal to $L+1=4$. The values of the channel is presented in the table \ref{tab:sisotable5}. The results of the GFDM performance are presented in the two plots, at first \eqref{fs_8} is shown the SER in comparison with the Zero-Forcing FFT receiver and with case for different number of unknown symbols in one transmission block. In the simulation we define as the unknown symbol number of the non-training symbols in the $vec(\mathbf{S})$ At second figure \eqref{fs_9} is shown the reconstruction error for the channel.

\section{Conclusion}\label{part:CSISO}
As conclusion for the first experiment we  can say that zero forced receiver show much better results in the symbol detection in comparison with matched filter. The difference become significant when the $roll-off$ factor of the $RRC$ filter increase. The ZF receiver has increased the SER slightly with $\alpha$ increasing which is shown at the fig.\ref{fs_1}. The MF receiver increase SER significantly more  with $\alpha$ increasing which is shown at fig.\ref{fs_2}. Explained results show, that ZF receiver should be preferred in the receiver. The ZF receiver achieve the better performance with the same self-interference ratio and allow to decrease the out-of-band radiation.
As conclusion for the experiment with frequency coefficient selection approach we can see that algorithm decrease SER for 5-6 dB in comparison with system which know the frequency coefficients fig.\ref{fs_3}. This significant decrease in performance come from the non-convenient coefficient selection way in algorithm, where coefficient was chosen as $1$ if the resulting $abs(a_1)$ value is higher that 0.5. There are possible better solutions which increase performance of the algorithm and approaches to use predefined information at the receiver. We can see that joint algorithm show slightly worse performance in symbol and frequency coefficients detection fig.\ref{fs_3}fig.\ref{fs_4}in comparison with approximated algorithms. Those behaviour is explained from the approximated algorithm convergence. We take as the start point transmission coefficients equal to the zero. The approximated algorithm turn on less sub-carriers and make false negative errors. The false negative error lead to the better SER performance due to less estimated number of the symbols. The possible performance increase for the joint solution algorithm is the different weights for the objective function parts. The part for frequency coefficients estimations should have higher weight.
The third experiment shows advantages of the joint algorithm. As we can see from the all three figures \ref{fs_5},\ref{fs_6},\ref{fs_7}. The residual decrease show that joint solution algorithm converge much faster than approximated. The typical number of iteration of the joint algorithm equal to $2$ and for the joint algorithm equal to the $200$. So significant difference neglect the difference between the computationally expensive iterations in the joint algorithm. The fig. \ref{fs_6} confirm that fact. The joint algorithm converge independently from the SNR and take 100 times less time to converge. The approximated algorithm slightly depend from the SNR in the received data.
The fig. \ref{fs_7} show that estimated values in the approximated algorithm decrease non-linearly. The shown fact mean that algorithm decrease at each iteration only one set of the variables, symbols or frequency coefficients. The overall conclusion is that approach is effective enough for the data estimation and there are possibility to increase performance with weights addition. Algorithm will show slightly better results.
The next experiment is estimated the frequency selective channel estimation approach. The experiment was done for the all possible number of known symbols which have certain problem statement. The result for the SER if shown in the fig. \ref{fs_8}. As we can see here, there is one minimum point in symbol estimation. The less unknown symbols in the block leads to the SNR increase, whether the higher number of unknown symbols leads to the SER increase. The point where number of unknown symbols equal to $8$ show the closest result to the original GFDM system with the same block size but known channel and ZF receiver. The channel estimation error has the same behaviour and show the minimum point in the same number of unknown symbols. Important fact is that reconstruction error for the maximal and minimal number of unknown symbols have the same behaviour and lay in the same line. Which mean that maximum knowledge and maximal uncertainty show the same results. This behaviour also show the convexity of the performance function for the number of unknown symbols as variable. In the difference block size should be different optimal value of the unknown symbols, but the average performance must be the worse in comparison with the original GFDM system due to the higher energy per bit with same performance. There is additional important performance gain in the explained algorithm, the algorithm decrease the self-interference in the system from known symbols. The algorithm also can be written for the overall interference decrease, but better to use this algorithm after the semi-blind receiver.
